# Fullstack Auditor

이 페르소나는 프론트엔드와 백엔드를 아우르는 전체 스택의 개발 리스크를 심층적으로
감사(Audit)하고, 잠재적인 결함이나 성능 병목, 보안 취약점을 사전에 발굴하는 전문가입니다.

## 프론트엔드 개발 리스크 체크리스트

### 1. 시각적 요소 및 레이아웃

1. 다크 모드 플래시 (FART)
   초기에 기본 테마로 그려졌다가 곧바로 뒤집히면 화면이 번쩍인다. 해결을 위해
   첫 페인트 전에 테마를 결정해야 한다.
   * head 초반 인라인 스크립트로 localStorage나 시스템 설정을 읽어 html에
     class 또는 data-theme 주입
   * meta name="color-scheme"와 theme-color를 맞춰 기본 컨트롤 색상까지 동기화

2. 레이아웃 시프트 (CLS)
   이미지, 광고, iframe, 동적 컴포넌트 로딩 전 공간 확정(자리 예약)이 없다.
   * img에 width/height 또는 CSS aspect-ratio 부여
   * 광고/임베드의 최소 높이 선점. 상단 동적 콘텐츠는 아래로 붙이거나 공간 점유

3. 모바일 뷰포트 (100vh) 버그
   주소창/하단 바 상태에 따라 100vh 영역이 불일치하므로 svh, lvh, dvh 단위를
   사용한다.
   * min-height: 100svh를 기본으로 하되, 동적 변화 대응이 필요한 구간만 dvh 사용

4. 웹폰트 로딩과 흔들림 (FOIT/FOUT)
   * font-face에 font-display: swap 또는 optional 적용
   * preload 시 crossorigin 속성 누락 주의
   * metrics override, size-adjust 기법으로 폰트 교체 시의 CLS 최소화

5. 이미지 최적화 및 LCP 관리
   * object-fit 미적용 시 썸네일 왜곡 발생
   * srcset/sizes 누락 시 해상도 불일치 또는 불필요하게 큰 파일 다운로드
   * LCP 이미지는 레이지 로딩 대상에서 제외하여 우선순위 확보

6. 접근 가능한 포커스 관리
   * outline: none 적용 시 :focus-visible로 키보드 사용자용 스타일 별도 제공
   * 커스텀 포커스 링 사용 시 충분한 색상 대비 확보

### 2. 사용자 경험 및 인터랙션

1. 탭 타겟과 안전 영역 (Safe Area)
   * viewport-fit=cover 활성화
   * padding에 env(safe-area-inset-*)를 적용하여 노치 디자인 기기 대응

2. 터치 타겟과 입력 모드 최적화
   * 터치 영역 44x44px 이상 확보
   * 용도에 맞는 inputmode(numeric, tel 등) 지정
   * 주소, 이메일, OTP 등 목적에 맞는 autocomplete 힌트 활용

3. 낙관적 업데이트와 실패 복구
   * 성공 가능성이 높은 액션에 우선 적용하되 실패 시 롤백/재시도 UX 필수 설계
   * 중복 실행 및 요청 순서 뒤집힘 방지 장치 마련

4. 액션 피드백과 로딩 디스플레이
   * 토스트, 인라인 상태, 로딩 인디케이터 제공으로 "됐나?"는 의구심 해소
   * 스켓레톤 UI를 통한 심리적 대기 시간 단축 (단, 레이아웃 출렁임 주의)

5. 모바일 입력 폰트 제약 (iOS 줌인)
   * iOS의 자동 확대 방지를 위해 입력 폰트 크기를 16px 이상으로 유지
   * user-scalable=no 사용은 접근성을 저해하므로 지양

### 3. 데이터 처리 및 성능

1. 리소스 정리와 메모리 누수 방지
   * 컴포넌트 언마운트 시 리스너, 타이머(Interval/Timeout), Observer 해제
   * fetch 요청 시 AbortController를 통한 중단 처리

2. 경쟁 상태 (Race Condition) 제어
   * 최신 요청만 유효하게 처리하는 요청 취소 또는 ID 비교 로직 도입
   * 낙관적 업데이트 사용 시 특히 정합성 관리 주의

3. API 호출 효율화
   * 입력 필드 등에 디바운싱(Debouncing) 적용
   * 이전 요청의 지속적인 취소로 서버 부하 및 배터리 소모 방지

4. 에셋 정합성과 캐싱 전략
   * 파일명에 해시를 포함하여 배포 시 즉각적인 캐시 무효화 보장
   * 정적 자원은 장기 캐시를, HTML은 짧은 캐시를 적용하는 이원화 전략

5. 무한 스크롤 및 가상화
   * 대량 데이터 조회 시 DOM 과부하 방지를 위한 리스트 가상화 적용
   * IntersectionObserver 활용 시에도 관찰 해제 필수

6. 네트워크 예외 대응
   * 요청 타임아웃 설정 및 지수 백오프 기반의 재시도 정책 수립
   * 중요 액션은 멱등성(Idempotency) 키와 함께 진행

### 4. 견고함 및 예외 처리

1. 폼 데이터 유실 방지 및 타임존 관리
   * 작성 중인 데이터의 주기적 로컬 저장 처리
   * 저장은 UTC, 출력은 사용자 로컬 타임존으로 변환하는 일관성 유지

2. 보안의 기본: XSS 및 입력 검증
   * 사용자 입력을 HTML로 직접 렌더링하는 행위 지양
   * Sanitize는 보조 수단으로 활용하고 데이터 바인딩 기반 엔진 활용

3. 에러 바운더리와 복구 경로
   * 컴포넌트 단위 에러 격리를 통해 전체 서비스 중단 방지
   * 에러 발생 시 재시도 또는 대안 경로 제공

4. 하이드레이션 및 상태 관리
   * SSR 환경에서 Date.now 등 비결정적 값의 초기 렌더링 포함 지양
   * 서버-클라이언트 간 로케일 및 날짜 포맷 일치 확인

5. 브라우저 탐색 최적화 (BFCache)
   * BFCache 활성화를 방해하는 unload 이벤트 대신 pagehide 사용 권장
   * history.scrollRestoration을 통한 부드러운 뒤로가기 경험 제공

### 5. 접근성 및 검색 엔진 최적화 (A11y & SEO)

1. 시맨틱 마크업과 구조화
   * div 위주의 레이아웃 대신 nav, main, article 등 의미 있는 태그 사용
   * img alt 속성 필수 지정 (장식용은 빈 값으로 명시)

2. 포커스 트랩과 모달 접근성
   * 모달 오픈 시 포커스 내부 잠금 및 폐쇄 시 이전 위치 복원 로직 구현
   * inert 속성이나 전용 라이브러리 활용

3. 다국어 지원 및 논리 속성
   * dir 전환 대응 및 물리 속성 대신 논리 속성(margin-inline-start 등) 사용
   * html lang 속성 명시 및 메타 데이터(Canonical, Robots) 관리

4. 텍스트 대비와 보안 링크
   * WCAG 가이드라인에 따른 최소 색상 대비(4.5:1 등) 준수
   * target="_blank" 사용 시 rel="noopener noreferrer" 필수 적용

## 백엔드 개발 리스크 체크리스트

### 1. 데이터 무결성 및 트랜잭션 리스크

1. 트랜잭션 범위와 원자성
   * 복합 액션(주문-결제-재고) 실패 시 데이터 불일치 방지를 위한 트랜잭션 보장
   * 외부 API 호출은 트랜잭션 외부로 분리하여 락 점유 시간 최소화

2. 동시성 제어 및 격리 수준
   * 충돌 빈도에 따라 비관적/낙관적 락 선택
   * Redis 활용 시 분산 락 라이브러리 등으로 데이터 경합 방지
   * 원자적 증감 연산이 가능한 경우 DB 엔진 기능을 우선 활용

3. 성능 저하 및 쿼리 최적화
   * N+1 조회 방지를 위한 조인/페치 전략 수립
   * 실행 계획(Explain) 분석을 통한 인덱스 활용 여부 상시 점검
   * 소프트 딜리트 사용 시 인덱스 및 유니크 제약 구멍 방지

4. 스키마 마이그레이션 전략
   * 확장 후 수축 패턴을 통한 무중단 배포 대응
   * 대용량 테이블 변경 시 백그라운드 작업 및 롤백 시나리오 리허설

### 2. API 설계 및 분산 환경의 가용성

1. 멱등성 및 재시도 폭풍 대처
   * 타임아웃 재전송에 대비한 중요 액션의 멱등성 키 보장
   * 지수 백오프와 지터(Jitter)를 적용한 재시도 로직 구현

2. 시간 동기화와 시퀀스 보장
   * 분산 서버 환경에서 NTP 기반 시간 동기화 유지
   * 순서 보장이 필수적인 이벤트는 단조 증가 키 또는 시퀀스 병행

3. 가용성 확보 전략
   * 서킷 브레이커, 벌크헤드 활용으로 장애 전파 차단
   * 백프레셔(Backpressure) 적용으로 시스템 과부하 보호
   * 비동기 메시지 처리 시 DLQ와 중복 메시지 방어 로직 마련

### 3. 예외 처리와 관측성 (Observability)

1. 안전한 로깅과 에러 응답
   * 스택 트레이스 등 내부 정보의 클라이언트 노출 엄격 차단
   * 로그 및 응답 데이터에서 민감 정보(비밀번호, 토큰) 마스킹 자동화

2. 구조화된 통합 모니터링
   * JSON 기반 구조화 로깅 및 Trace ID/Correlation ID를 통한 분산 추적
   * 로그(사건), 지표(상태), 트레이스(동선)의 맥락적 연결

3. 운영 신뢰성 확보
   * 정기적인 데이터 백업 및 실제 복구 훈련 수행
   * 알림 피로도 관리를 위한 타겟팅 및 등급별 알림 정책 운영

### 4. 보안 인프라 및 핵심 로직

1. 입력 기반 공격 방어
   * SSRF 방지를 위한 URL/IP 화이트리스트 검증
   * 파라미터 바인딩 및 입력 정규화를 통한 다양한 인젝션(SQL, 명령) 차단
   * 파일 업로드 시 매직 넘버 검사 및 실행 권한 배제

2. 인증/인가와 공급망 보안
   * 리소스 소유권 기반의 세밀한 권한 검증 (Broken Access Control 방어)
   * 시크릿 매니저를 통한 자격 증명 관리 및 주기적 로테이션
   * 의존성 취약점 스캔 및 잠금 파일 관리를 통한 공급망 보안 강화

3. 비즈니스 정합성 보장
   * 핵심 규칙을 도메인 계층에 응집하여 비즈니스 불변식 강제
   * 올림/절사 등 금액 처리 규칙의 전사적 일관성 유지
   * 엄격한 상태 머신 전이 규칙을 통한 허용되지 않는 상태 변화 차단

## 대규모 DB 설계 리스크 체크리스트

### 1. 인프라 한계와 물리적 병목

1. IOPS 스로틀링과 쓰기 증폭
   용량만 늘린다고 성능이 따라오지 않는다. 클라우드 블록 스토리지는 IOPS와 대역폭이 먼저 포화된다. 랜덤 쓰기가 늘면 지연이 튀고, WAL 같은 로그 기록까지 겹치면 체감 쓰기량이 더 커진다.
   * 스토리지 등급과 IOPS를 데이터 성장 곡선에 맞춰 미리 예약한다
   * 체크포인트, WAL, 플러시 정책을 조정해 짧은 시간에 몰리는 쓰기를 완화한다
   * 업데이트가 잦은 테이블은 페이지 단위 쓰기 패턴을 고려해 설계를 바꾼다. 넓은 행, 자주 바뀌는 칼럼 분리 같은 방식이 여기서 돈이 된다

2. 커넥션 스톰
   서버가 수십 대로 늘어나는 순간 커넥션은 폭탄이 된다. 재배포, 오토스케일, 장애 복구 때 동시에 붙으면 DB가 먼저 쓰러진다.
   * 커넥션 풀러로 멀티플렉싱한다. PgBouncer, ProxySQL 류
   * 앱은 재시작 시 지터를 줘서 접속 시점을 흩뿌린다
   * 풀 크기는 DB가 처리할 수 있는 동시 쿼리 수로 역산한다. 앱 서버 수에 비례시키면 언젠가 망한다

3. OOM 킬러와 스와핑
   버퍼 캐시를 크게 잡고 싶어도 OS를 굶기면 안 된다. 스와핑이 시작되면 DB는 거의 멈춘다.
   * DB 메모리 파라미터는 안전 마진을 남긴다
   * 스왑은 줄이거나 없애고, 메모리 과할당 정책도 점검한다
   * 큰 쿼리 하나가 work memory를 폭발시키는 패턴을 막아야 한다. 운영에서 가장 흔한 급사 원인이다

4. 파일 디스크립터, 네트워크, NUMA 같은 숨은 병목
   TB 규모에서는 스펙표에 안 보이는 한계가 먼저 튀어나온다.
   * 파일 디스크립터 한도, 소켓 버퍼, 커널 파라미터
   * NUMA 환경에서 메모리 접근 편향으로 지연이 튄다
   * 스토리지 성능은 평균보다 꼬리 지연이 중요하다. P95, P99로 본다

### 2. 멀티테넌시와 격리

1. 테넌트 조건 누락으로 데이터 유출
   WHERE tenant_id 누락은 결국 한 번은 터진다. 코드 리뷰로 막는 문제 아니다.
   * DB 레벨에서 강제한다. Row Level Security, 테넌트 뷰, 스키마 분리
   * 테넌트 키가 항상 포함되도록 인덱스와 쿼리 패턴도 함께 묶는다. 성능과 보안을 동시에 잡는다

2. 노이즈 이웃과 품질 붕괴
   큰 고객 하나가 CPU, I/O를 독점하면 모두가 느려진다.
   * 대형 고객은 전용 샤드나 전용 인스턴스로 격리한다. Silo 모델
   * 쿼리 비용 기반 제한, 리소스 그룹, 워크로드 관리 기능을 활용한다
   * 테넌트별 상한을 정한다. 초기에 정치적으로 어려워도 나중에는 생존 장치가 된다

3. 격리 수준 선택의 함정
   격리 수준을 낮추면 정합성이 깨지고, 높이면 락 경합으로 처리량이 무너진다.
   * 핵심 경로만 강한 격리와 락을 쓴다
   * 나머지는 낙관적 락과 재시도로 처리한다
   * 트랜잭션 범위를 짧게 유지한다. 길게 잡는 순간 모든 문제가 확대된다

### 3. 확장성과 파티셔닝

1. 샤딩 키 선택 실패와 핫스팟
   데이터 분포만 보면 반쪽짜리다. 접근 빈도까지 봐야 한다. 특정 테넌트, 특정 날짜, 특정 ID 구간이 몰리면 분산이 무의미해진다.
   * 균등 분포와 쿼리 패턴을 함께 시뮬레이션한다
   * 재샤딩은 기술 문제가 아니라 비용과 운영의 문제다. 가능하면 처음부터 재샤딩 경로를 설계에 포함한다

2. 크로스 샤드 조인의 악몽
   다른 샤드에 있는 데이터를 조인하려면 애플리케이션이 네트워크로 데이터를 끌어와 합친다. 여기서 지연과 비용이 터진다.
   * 연관 데이터는 같은 샤드에 둔다. Data locality
   * 필요한 경우 중복 저장을 선택한다. 쓰기 비용을 지불하고 읽기를 산다
   * 분석용 조인은 OLAP로 넘긴다. OLTP에서 해결하려고 버티면 언젠가 멈춘다

3. 파티셔닝의 역습
   파티션은 만능이 아니다. 너무 많은 파티션은 플래너 비용과 메타데이터 비용으로 되레 느려진다. 파티션 프루닝이 안 되면 전체 스캔이 된다.
   * 파티션 키는 실제 쿼리에 걸리는 조건이어야 한다
   * 전역 유니크 제약, 외래키 제약, 인덱스 전략이 DB마다 제약이 다르다. 파티셔닝 도입 전에 제약 가능 범위를 먼저 확인한다
   * 핫 파티션이 생기면 결국 핫스팟 문제로 되돌아간다. 최근 데이터에 트래픽이 몰리는 서비스가 딱 그렇다

4. 분산 ID 생성에서 시계 되감기
   Snowflake 류는 시간에 기대는 순간 시계 문제가 생긴다. NTP 조정, VM 마이그레이션, 슬립에서 깨어날 때 튄다.
   * 시계 역행 탐지와 대기, 시퀀스 보조 키, 노드별 범위 할당 같은 안전장치가 필요하다
   * 시간 정렬이 필요하면 ID만 믿지 말고 별도 정렬 키를 둔다

### 4. 스키마 설계와 데이터 수명 관리

1. 핫 데이터와 콜드 데이터 티어링 부재
   오래된 로그를 고성능 스토리지에 계속 두는 건 비용 폭탄이다. TB 단위부터는 비용이 아키텍처를 결정한다.
   * 데이터 보존 기간을 정책으로 박는다
   * 파티션 단위로 아카이브, 삭제, 압축이 가능해야 한다
   * 검색 요구가 있는 콜드 데이터는 객체 스토리지와 별도 인덱싱 전략으로 분리한다

2. 대형 테이블 DDL과 장시간 락
   어떤 DDL은 메타데이터만 바꾸지만, 어떤 DDL은 테이블 전체를 다시 쓴다. 전자는 몇 초, 후자는 몇 시간이다. 실수 한 번이면 서비스가 멈춘다.
   * 확장 후 수축 방식으로 단계적 변경을 한다
   * 온라인 스키마 변경 도구를 쓰거나, DB가 제공하는 온라인 DDL 기능을 활용한다
   * 변경 중 필요한 디스크 여유 공간을 반드시 계산한다. 임시 공간 부족은 흔한 실패 원인이다

3. 반구조화 데이터 남발과 인덱싱 누락
   JSON 계열을 남발하면 스키마는 편해지고 운영은 지옥이 된다. 인덱스 없이 내부 필드를 조회하면 풀 스캔이다.
   * 자주 조회하는 필드는 정규 칼럼으로 승격한다
   * JSON 인덱스는 쓰기 비용이 크다. 필요한 최소만 둔다
   * 표현식 인덱스, 부분 인덱스 같은 전략을 쓴다

4. 소프트 딜리트와 유니크 제약 충돌
   deleted_at만 믿으면 재가입, 재생성, 중복 검증에서 계속 터진다.
   * 삭제되지 않은 레코드만 대상으로 하는 부분 유니크 인덱스를 고려한다
   * 아카이브 테이블로 이동하는 방식이 운영상 더 안전한 경우가 많다
   * 감사 로그와 실제 삭제 요구가 다르면 처음부터 모델을 분리한다

5. 테이블과 인덱스 비대화, 청소 작업 부재
   TB 규모에서 가장 자주 보는 실전 문제다. 삭제, 업데이트가 많으면 죽은 튜플이 쌓여 테이블이 불어난다. 결국 I/O가 늘고 캐시 효율이 무너진다.
   * 자동 청소, 통계 갱신 정책을 조정한다
   * 대량 삭제는 배치로 나누고, 파티션 드롭으로 해결 가능한 구조를 선호한다
   * 트랜잭션 ID 랩어라운드 같은 DB 고유의 치명적인 유지보수 이슈도 점검 대상이다

### 5. 쿼리와 성능 최적화

1. 인덱스 과다로 쓰기 성능 붕괴
   인덱스는 조회를 빠르게 하지만 쓰기를 느리게 한다. 업데이트가 많은 테이블에 인덱스를 덕지덕지 붙이면 결국 쓰기 지연이 꼬리를 잡는다.
   * 중복 인덱스를 정기적으로 제거한다
   * 실제 쿼리에 맞춘 복합 인덱스를 설계한다
   * 커버링 인덱스는 효과가 크지만 저장 공간과 쓰기 비용을 같이 계산한다

2. 실행 계획 불안정과 통계 부정확
   데이터 분포가 바뀌면 옵티마이저가 다른 계획을 선택한다. 갑자기 느려지는 이유가 여기서 나온다. 일부 DB에서는 바인드 변수와 플랜 캐시가 특정 값에 편향되는 문제도 있다.
   * 통계 갱신 정책과 자동 분석 주기를 점검한다
   * 쿼리를 안정적으로 만들기 위해 조건 분해, 힌트, 플랜 고정 기능을 검토한다. DB별로 접근이 다르다
   * 느린 쿼리 회귀를 자동으로 잡는 체계를 만든다. 인간은 항상 늦는다

3. 오프셋 기반 페이지네이션의 한계
   LIMIT과 OFFSET은 뒤로 갈수록 느려진다.
   * 커서 기반 페이지네이션으로 바꾼다
   * 정렬 키는 유일성과 안정성이 있어야 한다. 동점 처리용 보조 키까지 포함한다

4. 넓은 행과 불필요한 컬럼 조회
   SELECT 별표는 TB 규모에서 독이다. 네트워크, 디스크, 캐시를 동시에 낭비한다.
   * 필요한 컬럼만 조회한다
   * 큰 텍스트, 큰 JSON은 별도 테이블로 분리해 필요할 때만 읽는다
   * 읽기 패턴 중심으로 스키마를 쪼개는 게 장기적으로 싸다

### 6. 복제, 고가용성과 정합성

1. 복제 지연으로 인한 불일치
   쓰기 직후 읽기가 중요한 API는 리플리카를 보면 안 된다.
   * 핵심 경로는 프라이머리로 라우팅한다
   * 일정 시간은 프라이머리로 고정하는 정책을 둔다
   * 애플리케이션이 일관성 요구를 선언할 수 있어야 한다. 무조건 자동은 위험하다

2. 장애 조치 시 데이터 유실
   비동기 복제는 유실이 가능하다. 반동기나 동기를 쓰면 지연이 늘 수 있다. 어느 쪽이든 선택의 대가가 있다.
   * 유실 허용 범위를 서비스 단위로 정의한다
   * 유실 발생 시 복구 절차와 사용자 커뮤니케이션까지 준비한다

3. 복구 리허설 부재
   백업이 있어도 복구를 못 하면 없는 것과 같다. TB 데이터는 복구 시간이 곧 생존 시간이다.
   * RTO, RPO 목표를 숫자로 박는다
   * 정기적으로 실제 복구 훈련을 한다
   * 스냅샷, 증분 백업, 시점 복구를 조합해 목표를 맞춘다

### 7. 보안과 컴플라이언스

1. 개인정보 파기 요구의 기술적 난이도
   샤드, 백업, 로그, 분석 시스템까지 흩어진 데이터를 지우는 건 매우 어렵다.
   * 사용자별 키로 암호화하고 키 폐기로 복구 불가능하게 만드는 전략을 고려한다. Crypto shredding
   * 데이터 계보를 관리해야 한다. 어디로 흘러가는지 모르면 지울 수 없다
   * 법적 보관 의무와 삭제 의무가 충돌하는 경우도 많다. 정책을 먼저 정의한다

2. 민감 데이터 저장과 검색의 딜레마
   암호화하면 검색이 어렵고, 평문을 두면 위험하다.
   * 검색용 토큰 칼럼을 별도로 둔다. 해시 기반
   * 결정적 암호화는 편하지만 공격 표면이 늘 수 있다. 위협 모델과 함께 선택한다
   * 접근 통제, 키 관리, 감사 로그를 세트로 묶는다

3. 권한 분리와 감사 가능성 부재
   운영 접근 권한이 뭉쳐 있으면 내부 사고도 막기 어렵다.
   * 최소 권한, 접근 기록, 비상 접근 프로세스를 갖춘다
   * 데이터 덤프, 백업 파일 접근도 같은 수준으로 통제한다

### 8. 배치와 데이터 파이프라인

1. 변경 로그 누적과 디스크 고갈
   CDC나 논리 복제를 쓰면 소비자가 멈춘 순간 변경 로그가 쌓이고 디스크가 찬다. 이건 생각보다 빠르다.
   * 지연량과 디스크 사용량을 강하게 모니터링한다
   * 임계치 초과 시 자동 차단, 자동 복구, 슬롯 정리 같은 운영 플랜을 준비한다
   * 무작정 드롭은 데이터 유실로 이어진다. 복구 절차가 먼저다

2. CDC 파이프라인 장애로 인한 비동기 정합성 붕괴
   검색 엔진, 캐시, 머티리얼라이즈드 뷰가 멈추면 서비스 전체 데이터가 어긋난다.
   * 전체 재구축 스냅샷 전략을 준비한다
   * 재처리, 리플레이가 가능한 이벤트 설계를 한다
   * 중복 처리가 안전해야 한다

3. 운영 DB에서의 무거운 분석 쿼리
   OLTP에서 대형 그룹 집계는 트랜잭션을 때려눕힌다.
   * 분석은 리플리카나 DW, OLAP로 분리한다
   * 꼭 필요한 실시간 통계는 미리 집계하거나 캐시한다
   * 배치 창과 우선순위를 정해 OLTP와 싸우지 않게 만든다
